Jupyter Notebook
Part_I_exploration
Last Checkpoint: letzten Montag um 22:46 Uhr
Autosave Failed!
Current Kernel Logo
Python 3 
File
Edit
View
Insert
Cell
Kernel
Widgets
Help

Markdown
Part I - (Dataset Exploration Title)
by (Jana)
Introduction
Introduce the dataset

Rubric Tip: Your code should not generate any errors, and should use functions, loops where possible to reduce repetitive code. Prefer to use functions to reuse code statements.

Rubric Tip: Document your approach and findings in markdown cells. Use comments and docstrings in code cells to document the code functionality.

Rubric Tip: Markup cells should have headers and text that organize your thoughts, findings, and what you plan on investigating next.

Preliminary Wrangling
# import all packages and set plots to be embedded inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
​
%matplotlib inline
Load in your dataset and describe its properties through the questions below. Try and motivate your exploration goals through this section.

# load the fordgobike trip dataframe:
bike = pd.read_csv('201902-fordgobike-tripdata.csv')
# look into the shape and structure of the dataset
bike.head()
duration_sec	start_time	end_time	start_station_id	start_station_name	start_station_latitude	start_station_longitude	end_station_id	end_station_name	end_station_latitude	end_station_longitude	bike_id	user_type	member_birth_year	member_gender	bike_share_for_all_trip
0	52185	2019-02-28 17:32:10.1450	2019-03-01 08:01:55.9750	21.0	Montgomery St BART Station (Market St at 2nd St)	37.789625	-122.400811	13.0	Commercial St at Montgomery St	37.794231	-122.402923	4902	Customer	1984.0	Male	No
1	42521	2019-02-28 18:53:21.7890	2019-03-01 06:42:03.0560	23.0	The Embarcadero at Steuart St	37.791464	-122.391034	81.0	Berry St at 4th St	37.775880	-122.393170	2535	Customer	NaN	NaN	No
2	61854	2019-02-28 12:13:13.2180	2019-03-01 05:24:08.1460	86.0	Market St at Dolores St	37.769305	-122.426826	3.0	Powell St BART Station (Market St at 4th St)	37.786375	-122.404904	5905	Customer	1972.0	Male	No
3	36490	2019-02-28 17:54:26.0100	2019-03-01 04:02:36.8420	375.0	Grove St at Masonic Ave	37.774836	-122.446546	70.0	Central Ave at Fell St	37.773311	-122.444293	6638	Subscriber	1989.0	Other	No
4	1585	2019-02-28 23:54:18.5490	2019-03-01 00:20:44.0740	7.0	Frank H Ogawa Plaza	37.804562	-122.271738	222.0	10th Ave at E 15th St	37.792714	-122.248780	4898	Subscriber	1974.0	Male	Yes
bike.tail()
duration_sec	start_time	end_time	start_station_id	start_station_name	start_station_latitude	start_station_longitude	end_station_id	end_station_name	end_station_latitude	end_station_longitude	bike_id	user_type	member_birth_year	member_gender	bike_share_for_all_trip
183407	480	2019-02-01 00:04:49.7240	2019-02-01 00:12:50.0340	27.0	Beale St at Harrison St	37.788059	-122.391865	324.0	Union Square (Powell St at Post St)	37.788300	-122.408531	4832	Subscriber	1996.0	Male	No
183408	313	2019-02-01 00:05:34.7440	2019-02-01 00:10:48.5020	21.0	Montgomery St BART Station (Market St at 2nd St)	37.789625	-122.400811	66.0	3rd St at Townsend St	37.778742	-122.392741	4960	Subscriber	1984.0	Male	No
183409	141	2019-02-01 00:06:05.5490	2019-02-01 00:08:27.2200	278.0	The Alameda at Bush St	37.331932	-121.904888	277.0	Morrison Ave at Julian St	37.333658	-121.908586	3824	Subscriber	1990.0	Male	Yes
183410	139	2019-02-01 00:05:34.3600	2019-02-01 00:07:54.2870	220.0	San Pablo Ave at MLK Jr Way	37.811351	-122.273422	216.0	San Pablo Ave at 27th St	37.817827	-122.275698	5095	Subscriber	1988.0	Male	No
183411	271	2019-02-01 00:00:20.6360	2019-02-01 00:04:52.0580	24.0	Spear St at Folsom St	37.789677	-122.390428	37.0	2nd St at Folsom St	37.785000	-122.395936	1057	Subscriber	1989.0	Male	No
bike.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 183412 entries, 0 to 183411
Data columns (total 16 columns):
duration_sec               183412 non-null int64
start_time                 183412 non-null object
end_time                   183412 non-null object
start_station_id           183215 non-null float64
start_station_name         183215 non-null object
start_station_latitude     183412 non-null float64
start_station_longitude    183412 non-null float64
end_station_id             183215 non-null float64
end_station_name           183215 non-null object
end_station_latitude       183412 non-null float64
end_station_longitude      183412 non-null float64
bike_id                    183412 non-null int64
user_type                  183412 non-null object
member_birth_year          175147 non-null float64
member_gender              175147 non-null object
bike_share_for_all_trip    183412 non-null object
dtypes: float64(7), int64(2), object(7)
memory usage: 22.4+ MB
Not all Members have valid data in the birth_year and gender column. As these are interesting values I will drop the rows with NaN

The bike_id is a integer -> I am going to convert it to a str

gobike = bike.copy()
#only take the values with not NaN values
gobike = gobike[gobike['member_gender'].notna()]
gobike = gobike[gobike['start_station_id'].notna()]
# filter for all birht years above 1950
gobike = gobike[gobike['member_birth_year']>1949]
gobike['bike_id'] = gobike['bike_id'].apply(str)
gobike.info()
<class 'pandas.core.frame.DataFrame'>
Int64Index: 174278 entries, 0 to 183411
Data columns (total 16 columns):
duration_sec               174278 non-null int64
start_time                 174278 non-null object
end_time                   174278 non-null object
start_station_id           174278 non-null float64
start_station_name         174278 non-null object
start_station_latitude     174278 non-null float64
start_station_longitude    174278 non-null float64
end_station_id             174278 non-null float64
end_station_name           174278 non-null object
end_station_latitude       174278 non-null float64
end_station_longitude      174278 non-null float64
bike_id                    174278 non-null object
user_type                  174278 non-null object
member_birth_year          174278 non-null float64
member_gender              174278 non-null object
bike_share_for_all_trip    174278 non-null object
dtypes: float64(7), int64(1), object(8)
memory usage: 22.6+ MB
What is the structure of your dataset?
There are 183.412 Trips in this dataframe, described with 16 columns.

What is/are the main feature(s) of interest in your dataset?
I am interested if the subscribtion status has an influence on the total amount of bikerides.

What features in the dataset do you think will help support your investigation into your feature(s) of interest?
Your answer here!

Univariate Exploration
In this section, investigate distributions of individual variables. If you see unusual points or outliers, take a deeper look to clean things up and prepare yourself to look at relationships between variables.

Rubric Tip: The project (Parts I alone) should have at least 15 visualizations distributed over univariate, bivariate, and multivariate plots to explore many relationships in the data set. Use reasoning to justify the flow of the exploration.

Rubric Tip: Use the "Question-Visualization-Observations" framework throughout the exploration. This framework involves asking a question from the data, creating a visualization to find answers, and then recording observations after each visualisation.

# create a function for plotting the bar charts matplotlib
def bar_chart(a, b, col, rot):
    plt.figure(figsize = [10, 5]) 
    plt.bar(a, b, color = col);
    plt.xticks(rotation=rot);
# create a function for plotting bar charts sb 
# in case no oredr necessary d=None
def countplot(a, b, rot):
    plt.figure(figsize = [10, 5])
    sb.countplot(data=gobike, x= a, order= b);
    plt.xticks(rotation=rot);
#def axis(a,b,c):
    #achsenbeschriftung titel, x-achse, y-achse, rotation beschriftung:rot
gobike['start_station_name'].nunique()
329
gobike['end_station_name'].nunique()
329
start_name = gobike['start_station_name'].value_counts().head(10).index
start = gobike['start_station_name'].value_counts().head(10)
#creating a bar chart for the most used start station
bar_chart(start_name, start, 'pink', 90)

The station with the highest bike pick ups is the Market St at 10th St.

# second look at the station with the highest drop offs 
end_name = gobike['end_station_name'].value_counts().head(10).index
end = gobike['end_station_name'].value_counts().head(10)
#creating a bar chart for the most used end stations
bar_chart(end_name, end, 'blue', 90)
​

The station with the most drop offs is the: San Francisco Caltrain Station 2 (Townsend St at 4th St)

# a standard-scaled plot for the Genders of the Users
countplot('member_gender', None, 0)

The Amount of male users is about three times as high as females

# categorize the users in age groups
plt.figure(figsize = [15, 5])
​
# histogram of the full data
plt.hist(data = gobike, x = 'member_birth_year', bins = 15);

The histogram shows a right skewed diagram. with most customers are born between 1980 and 1995.

#next I will look at members with the status subscribers or customer 
countplot('user_type', None, 0)

As most of the users are subscribers I do not need to dig deeper into the diffrent user types.

#create new columns for the moth and the weekday when the bikes are used
gobike['start_time'] = pd.to_datetime(gobike['start_time'])
gobike['month'] = gobike['start_time'].dt.month
gobike['day_of_week'] = gobike['start_time'].dt.weekday_name
#create a weekday order
cats = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
#plot the weekdays with the most usages
countplot('day_of_week', cats, 45)

Most bikes are used on thursdays

# which month is the most frequented month
countplot('month', None, 0)

# surprisign result so I will doublecheck the data 
gobike['month'].nunique()
1
All bikes in this data set have been rented in February.

# what bike is used the most
bike_use = gobike['bike_id'].value_counts().head(10).index
usage = gobike['bike_id'].value_counts().head(10)
#creating a bar chart 
bar_chart(bike_use, usage, 'green', 90)

The most used bike is the bike with the number 4794

# next I will look into the ride data
# first figure out the longest and shortest ride time
max = gobike['duration_sec'].max()
maxh = max/3600
min = gobike['duration_sec'].min()
​
min, max, maxh
(61, 84548, 23.485555555555557)
> these ride times are quite wide spreaded, min ride time of 61 seconds is probably someone who redcided after renting the bike. the max time of 23.5 hours is quite long. 
2
# next I will check for more "outliers" close to the max riding time.
gobike['duration_sec'].sort_values().tail(20)
120711    69335
33431     69620
54376     69803
32098     69980
14381     70211
29922     70925
145977    71470
129177    72576
116671    72590
129176    72627
123383    73930
86454     74097
90195     74408
107581    79548
8631      81549
95750     82512
5203      83195
112435    83407
127999    83519
85465     84548
Name: duration_sec, dtype: int64
gobike['duration_sec'].mean()
704.25593591847507
There are constantly users who use the bike for several hours, though looking and the mean the average time is 704 seconds.

# Define the figure size
plt.figure(figsize = [20, 5])
​
# histogram on left: full data
plt.subplot(1, 2, 1)
bin_edges = np.arange(0, gobike['duration_sec'].max()+0.5)
plt.hist(data=gobike, x='duration_sec', bins=bin_edges)
​
# plot a histogram of the usage data but cut at mean+1000 seconds
plt.subplot(1, 2, 2)
bins = np.arange(0, gobike['duration_sec'].mean()+1000)
plt.hist(data=gobike, x='duration_sec', bins=bins);
plt.xlim(0, 6)
(0, 6)

The graph with the full data is left skewd but hard to read so I decided to plot a subplot with a closer look. the peak is around 500 seconds or 14 minutes or riding time.

Rubric Tip: Visualizations should depict the data appropriately so that the plots are easily interpretable. You should choose an appropriate plot type, data encodings, and formatting as needed. The formatting may include setting/adding the title, labels, legend, and comments. Also, do not overplot or incorrectly plot ordinal data.

​
Discuss the distribution(s) of your variable(s) of interest. Were there any unusual points? Did you need to perform any transformations?
To look at the weekday and monthly usage data I needed to extract the data from the start_date format.

The birth year has some unusual outliers. which was corrected to the first birthdate considert from 1950.

Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?
I removed the rows with missing values from the rows 'birth_year' and 'gender'. Also I removed the rows with missing values from 'start_station' and 'end_station'

in the original dataset the bike_id is a integer as this is more seen as a name I converted it to a string to use it as it were letters.

Bivariate Exploration
In this section, investigate relationships between pairs of variables in your data. Make sure the variables that you cover here have been introduced in some fashion in the previous section (univariate exploration).

Findings from above
combined stations usage
age groups vs gender
which user has the longest usage in total
# plot the top 10 most frequented combined stations
combined_name = (gobike['start_station_name'] + ' - ' + gobike['end_station_name']).value_counts().head(10).index
combined = (gobike['start_station_name'] + ' - ' + gobike['end_station_name']).value_counts().head(10)
bar_chart(combined_name, combined, 'navy', 90)

# plot the top 10 most frequented combined stations
combined_name = (gobike['start_station_name'] + ' - ' + gobike['end_station_name']).value_counts().head(10).index
combined = (gobike['start_station_name'] + ' - ' + gobike['end_station_name']).value_counts().head(10)
bar_chart(combined_name, combined, 'navy', 90)
​

The most used combination of stations are the: Berry St at 4th St - San Francisco Ferry Building (Harry Bridges Plaza)

The combination of the most frequented pick up station: 'Market St at 10th St' and the most frequented drop off station: 'San Francisco Caltrain Station 2 (Townsend St at 4th St)' is at the tenth place ov the most used combination stations.

# Age group vs gender 
# Age group vs gender 
# calculate age from birth year
# code line from Mentors-page
from datetime import date
​
def calculate_age(birthdate):
    today = date.today()
    age = today.year - birthdate
    
    return age
gobike['member_age'] = gobike['member_birth_year'].apply(lambda x: calculate_age(x)).astype(int)
gobike['member_age'].describe()
count    174278.000000
mean         37.018448
std           9.679385
min          21.000000
25%          30.000000
50%          35.000000
75%          42.000000
max          72.000000
Name: member_age, dtype: float64
member_gender
bins = [20 ,30, 40, 50, 60, 71]
labels = ['20-30 years','30-40 years','40-50 years', '50-60 years', '60-70 years']
gobike['bins'] = pd.cut(gobike['member_age'], bins=bins, labels=labels, include_lowest=True)
cats = gobike.groupby('member_gender')['bins'].value_counts().unstack('member_gender')
cats
member_gender	Female	Male	Other
bins			
20-30 years	11381	36053	742
30-40 years	19623	55553	1612
40-50 years	6226	23258	723
50-60 years	2705	10791	504
60-70 years	765	4126	38
cats.plot.bar(stacked=True);

Looking at the Graph all genders are most represented in the ages 30-40 years and second most in 20-30 years. As these are the total numbers I would like to see the change, when I look at the proportions.

.
#calculating the proportion of the gender
prop = gobike.groupby('member_gender')['bins'].value_counts(normalize=True).unstack('member_gender')
prop
member_gender	Female	Male	Other
bins			
20-30 years	0.279631	0.277799	0.205029
30-40 years	0.482138	0.428052	0.445427
40-50 years	0.152973	0.179210	0.199779
50-60 years	0.066462	0.083148	0.139265
60-70 years	0.018796	0.031792	0.010500
#plot the new chart
prop.plot.bar(stacked=True);

In the first plot looking at the total numbers; I could see the dominace of the male users. But looking at the proportions of each Gender group the representation of all three Gender types is the same. For more details I can look at the table printed and I can see there are slight differences but for this analysis I will neglect them.

Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?
The most common pick up station does not match the most frequented drop-off point. So I created a new plot that looked into the combination of pick up and drop off station. The combination of the most frequented pick up and drop off station does exist in the top 10 combinations but interestingly it is the least. The most used combination of stations are both found in the individual top 10 station picks on lower positions.

Categorizing the Age in 10 year steps to look at the gender representation as a total I clearly see the representation of Males is the highest in all Age groups. The Age Group 30-40 years is represented the most between Users and the Age Group 20-30 years is second most.

As lookign at the total numbers of representation it would be really interesting to see the representation of each gender in the age groups in proportion of the total representation of the three genders. And the Grpah changes completly. It shows that all genders are represented in each age group the same (a third each)

Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?
No I did not.

Multivariate Exploration
Create plots of three or more variables to investigate your data even further. Make sure that your investigations are justified, and follow from your work in the previous sections.

​
Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?
Your answer here!

Were there any interesting or surprising interactions between features?
Your answer here!

Conclusions
You can write a summary of the main findings and reflect on the steps taken during the data exploration.

Remove all Tips mentioned above, before you convert this notebook to PDF/HTML

At the end of your report, make sure that you export the notebook as an html file from the File > Download as... > HTML or PDF menu. Make sure you keep track of where the exported file goes, so you can put it in the same folder as this notebook for project submission. Also, make sure you remove all of the quote-formatted guide notes like this one before you finish your report!

​
